import argparse
import sys

from .utils import load_data, store_output, check_help

import cyzil


def _parse_argument(args, docs):
    parser = argparse.ArgumentParser(description=docs)
    parser.add_argument(
        "--reference",
        required=True,
        type=str,
        help=(
            "Path to a reference file (supervised sequence), where",
            "each serntence is separated by '\n'",
            "Make sure the path includes the file extension.",
            "e.g., --reference ref.fr to load French translation reference."
        )
    )
    parser.add_argument(
        "--candidate",
        required=True,
        type=str,
        help=(
            "Path to a candiate file (sequence generated by a model), where",
            "each serntence is separated by '\n'",
            "Make sure the path includes the file extension.",
            "e.g., --candiate cand.fr to load French translation candidates."
        )
    )
    parser.add_argument(
        "--tokenizer",
        default='space',
        choices=['space', 'nltk'],
        help=(
            "A method to tokenize input sentences.",
            "By default, a sentence is split by white spaces.",
            "options: space, nltk"
        )
    )
    parser.add_argument(
        "-o",
        "--output",
        type=str,
        help=(
            "A file path to store the output of `edit_distance_points`.",
            "It stores the output in csv format, where",
            "each row corresponds to a translation pair, and",
            "columns are in the following format: ",
            "edit distance, normalized edit distance"
        )
    )
    return parser.parse_args(args)


def edit_distance_corpus():
    """compute bleu score for each translation pair
    cyzi-edit-distance-corpus [-h] [--reference] [--candiate]
                              [--tokenizer]
    required arguments:
    --reference     path to reference file, where each serntence is separated by '\n'
    --candiate      path to candidate file, where each serntence is separated by '\n'

    optional arguments:
    --tokenizer     a way to tokenize sentences (white space by default);
                    options: space, nltk
    """
    check_help(edit_distance_corpus.__doc__)
    parser = _parse_argument(sys.argv[1:], edit_distance_corpus.__doc__)
    reference = load_data(parser.reference, parser.tokenizer)
    candidate = load_data(parser.candidate, parser.tokenizer)
    scores = cyzil.edit_distance_corpus(reference, candidate)
    print(
        "Edit distance:", scores[0],
        "\nNormalized edit distance:", scores[1],
    )


def edit_distance_points():
    """compute edit distance for each translation pair
    cyzil-edit-distance-points [-h] [--reference] [--candiate]
                               [--tokenizer] [--output]
    required arguments:
    --reference     path to reference file, where each serntence is separated by '\n'
    --candiate      path to candidate file, where each serntence is separated by '\n'

    optional arguments:
    --tokenizer     a way to tokenize sentences (white space by default);
                    options: space, nltk
    -o, --output    a file path to store output in csv format
    """
    check_help(edit_distance_points.__doc__)
    parser = _parse_argument(sys.argv[1:], edit_distance_points.__doc__)
    reference = load_data(parser.reference, parser.tokenizer)
    candidate = load_data(parser.candidate, parser.tokenizer)
    scores = cyzil.edit_distance_points(reference, candidate)
    if parser.output is not None:
        store_output(scores, parser.output)
    else:
        print(scores)
